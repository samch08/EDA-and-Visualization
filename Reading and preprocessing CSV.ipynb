{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"D:\\Sambita\\Training\\others\\BSE\\Gathering and pre-processing\\Employee data1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r\"D:\\Sambita\\Training\\others\\BSE\\Gathering and pre-processing\\Employee data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading  .CSV from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "download_url = \"https://raw.githubusercontent.com/fivethirtyeight/data/master/nba-elo/nbaallelo.csv\"\n",
    "target_csv_path = \"nba_all_elo.csv\"\n",
    "\n",
    "response = requests.get(download_url)\n",
    "with open(target_csv_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "print(\"Download ready.\")\n",
    "df_g=pd.read_csv(\"nba_all_elo.csv\")\n",
    "type(f)\n",
    "#z= open(target_csv_path, \"wb\")\n",
    "#print(\"z\",type(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car1 = pd.read_csv(r'D:\\Sambita\\Training\\others\\BSE\\Gathering and pre-processing\\car data.csv')\n",
    "car2 =pd.read_csv(r'D:\\Sambita\\Training\\others\\BSE\\Gathering and pre-processing\\car condition.csv')\n",
    "car1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car2= car1.merge(car2,left_on ='car id', right_on='car id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year']=df[\"bdate\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "dt = datetime.datetime(2012, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=df['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# multiply and add by random numbers to get some real values\n",
    "# Function to Detection Outlier on one-dimentional datasets.\n",
    "def find_anomalies(random_data):\n",
    "    anomalies = []\n",
    "    \n",
    "    # Set upper and lower limit to 3 standard deviation\n",
    "    random_data_std = random_data.std()\n",
    "    random_data_mean =random_data.mean()\n",
    "    anomaly_cut_off = random_data_std * 3\n",
    "    \n",
    "    lower_limit  = random_data_mean - anomaly_cut_off \n",
    "    upper_limit = random_data_mean + anomaly_cut_off\n",
    "    print(lower_limit)\n",
    "    # Generate outliers\n",
    "    for outlier in random_data:\n",
    "        if outlier > upper_limit or outlier < lower_limit:\n",
    "            anomalies.append(outlier)\n",
    "    return anomalies\n",
    "\n",
    "find_anomalies(df['salary'])# df.salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irrelevant data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "print(df.drop(axis=1, columns=['salbegin']))\n",
    "df[df['salary'] <= 57000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n",
    "print(df[df[\"prevexp\"].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(car2[\"horsepower\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(car2.isnull().sum())\n",
    "for i in range(len(car2[\"horsepower\"])):\n",
    "    if car2[\"horsepower\"].iloc[i] == \"?\":\n",
    "        car2[\"horsepower\"].iloc[i] = np.nan\n",
    "car2[\"horsepower\"] = pd.to_numeric(car2[\"horsepower\"])\n",
    "print(car2[car2[\"horsepower\"].isnull()])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['jobcat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot(df.salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=df['salary'].median()\n",
    "df['salary'].fillna(m,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "X= ['jobtime', 'prevexp','minority']\n",
    "imputer.fit(df[X])\n",
    "Xtrans = imputer.transform(df[X])\n",
    "df[X] = Xtrans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= df[df[\"id\"] == 49]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=df['minority'].mode()\n",
    "df['minority'].fillna(m1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,12))\n",
    "count=0\n",
    "for col, color in zip(['educ', 'jobcat', 'salary', 'salbegin', 'jobtime', 'prevexp'],['r','y','c','m','g','r']):\n",
    "    count+=1\n",
    "    if(count==col):\n",
    "        plt.subplot(1,6)\n",
    "    else:\n",
    "        plt.subplot(3,2,count)\n",
    "    sns.distplot(df[col],label=col,bins=50,  color=color)\n",
    "    plt.title('{} Distribution'.format(col), fontsize=15)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Normed Frequency', fontsize=15)\n",
    "    plt.xlabel(col, fontsize=15)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box cox transformation\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "import seaborn as sns\n",
    "fitted_data, fitted_lambda = stats.boxcox(df.salary)\n",
    "sns.distplot(df.salary, hist = False, kde = True,\n",
    "            kde_kws = {'shade': True, 'linewidth': 2}, \n",
    "            label = \"Non-Normal\", color =\"green\", ax = ax[0])\n",
    "  \n",
    "sns.distplot(fitted_data, hist = False, kde = True,\n",
    "            kde_kws = {'shade': True, 'linewidth': 2}, \n",
    "             color =\"green\", ax = ax[1], label = \"Salary\")\n",
    "  \n",
    "# adding legends to the subplots\n",
    "plt.legend(loc = \"upper right\")\n",
    "  \n",
    "# rescaling the subplots\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(10)\n",
    "print(fitted_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization with sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x = df.select_dtypes(exclude=[\"object\",\"datetime64[ns]\"])\n",
    "print(x.columns)\n",
    "x = x [['educ', 'salary', 'salbegin', 'jobtime', 'prevexp',\n",
    "      ]]\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(x)\n",
    "\n",
    "# transform training data\n",
    "df[['educ',  'salary', 'salbegin', 'jobtime', 'prevexp',\n",
    "      ]] = norm.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# apply standardization on numerical features\n",
    "num_cols = x.columns\n",
    "for i in num_cols:\n",
    "    \n",
    "    # fit on training data column\n",
    "    scale = StandardScaler().fit(x[[i]])\n",
    "    \n",
    "    # transform the training data column\n",
    "    df[i] = scale.transform(x[[i]])\n",
    "    \n",
    "    # transform the testing data column\n",
    "    df[i] = scale.transform(x[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "count=0\n",
    "for col, color in zip(['educ', 'jobcat', 'salary', 'salbegin', 'jobtime', 'prevexp'],['r','y','c','m','g','r']):\n",
    "    count+=1\n",
    "    if(count==col):\n",
    "        plt.subplot(1,6)\n",
    "    else:\n",
    "        plt.subplot(3,2,count)\n",
    "    sns.distplot(df[col],label=col,bins=50,  color=color)\n",
    "    plt.title('{} Distribution'.format(col), fontsize=15)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Normed Frequency', fontsize=15)\n",
    "    plt.xlabel(col, fontsize=15)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded=pd.get_dummies(data=df.jobcat1)#drop_first=True\n",
    "df=pd.concat([df,data_encoded],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='error',drop ='first')\n",
    "jc=enc.fit_transform(df.jobcat1.values.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc = pd.DataFrame(jc, columns = ['jc1', 'jc2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "l1= le.fit_transform(df.gender)\n",
    "l2= pd.DataFrame(l1, columns = [\"g1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.concat([df,l2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_con = pd.notnull(car2['Condition'])\n",
    "lcar=le.fit_transform(car2[not_null_con]['Condition'])\n",
    "car2=pd.concat([car2,pd.DataFrame(lcar, columns = [\"condtn_encode\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X= ['horsepower','condtn_encode']\n",
    "imputer.fit(car2[X])\n",
    "car2[X] = imputer.transform(car2[X])\n",
    "car2[X]= car2[X].round()\n",
    "car2 = car2.rename(columns ={'car id':'car_id'})\n",
    "print(car2[(car2['car_id']==33) | (car2['car_id']==127 ) ])\n",
    "\n",
    "print(car2.query('car_id == 393' or 'car_id == 394'))\n",
    "car2.condtn_encode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcar = pd.Categorical(car2[not_null_con]['Condition'])\n",
    "car2=pd.concat([car2,pd.DataFrame(lcar.codes, columns = [\"condtn_encode\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#car2['condtn_encode'] = car2['condtn_encode'].astype(str)\n",
    "car2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df[['educ', 'jobcat', 'salary', 'salbegin',\n",
    "       'jobtime', 'prevexp']].corr(),annot =True,vmax=1,vmin=-1,cmap=\"coolwarm\")\n",
    "#https://matplotlib.org/2.0.2/examples/color/colormaps_reference.html --cpolor references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "gender      0\n",
       "bdate       0\n",
       "educ        0\n",
       "jobcat      0\n",
       "salary      0\n",
       "salbegin    0\n",
       "jobtime     0\n",
       "prevexp     0\n",
       "minority    0\n",
       "jobcat1     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r\"D:\\Sambita\\Training\\others\\BSE\\Gathering and pre-processing\\Employee data1.xlsx\")\n",
    "\n",
    "df.salary.fillna(df[\"salary\"].median,inplace = True)\n",
    "df.jobtime.fillna(df[\"jobtime\"].median,inplace = True)\n",
    "df.prevexp.fillna(df[\"prevexp\"].median,inplace = True)\n",
    "df.minority.fillna(0,inplace = True)\n",
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "l1= le.fit_transform(df.gender)\n",
    "l2= pd.DataFrame(l1, columns = [\"g1\"])\n",
    "df2=pd.concat([df,l2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_encoded=pd.get_dummies(data=df2.jobcat1,drop_first=True)\n",
    "df2=pd.concat([df2,data_encoded],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 474 entries, 0 to 473\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   id                   473 non-null    float64       \n",
      " 1   gender               473 non-null    object        \n",
      " 2   bdate                473 non-null    datetime64[ns]\n",
      " 3   educ                 473 non-null    float64       \n",
      " 4   jobcat               473 non-null    float64       \n",
      " 5   salary               473 non-null    object        \n",
      " 6   salbegin             473 non-null    float64       \n",
      " 7   jobtime              473 non-null    object        \n",
      " 8   prevexp              473 non-null    object        \n",
      " 9   minority             473 non-null    float64       \n",
      " 10  jobcat1              473 non-null    object        \n",
      " 11  g1                   473 non-null    float64       \n",
      " 12  Manager              474 non-null    uint8         \n",
      " 13  Technical Architect  474 non-null    uint8         \n",
      "dtypes: datetime64[ns](1), float64(6), object(5), uint8(2)\n",
      "memory usage: 49.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 469 entries, 0 to 472\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   id                   469 non-null    float64       \n",
      " 1   gender               469 non-null    object        \n",
      " 2   bdate                469 non-null    datetime64[ns]\n",
      " 3   educ                 469 non-null    float64       \n",
      " 4   jobcat               469 non-null    float64       \n",
      " 5   salary               469 non-null    object        \n",
      " 6   salbegin             469 non-null    float64       \n",
      " 7   jobtime              469 non-null    float64       \n",
      " 8   prevexp              469 non-null    float64       \n",
      " 9   minority             469 non-null    float64       \n",
      " 10  jobcat1              469 non-null    object        \n",
      " 11  g1                   469 non-null    float64       \n",
      " 12  Manager              469 non-null    uint8         \n",
      " 13  Technical Architect  469 non-null    uint8         \n",
      "dtypes: datetime64[ns](1), float64(8), object(3), uint8(2)\n",
      "memory usage: 48.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df2.info())\n",
    "df2['jobtime'] = pd.to_numeric(df2['jobtime'], errors='coerce')\n",
    "df2['prevexp'] = pd.to_numeric(df2['prevexp'], errors='coerce')\n",
    "\n",
    "df2.dropna(inplace=True)\n",
    "print(df2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# visualize the PCA scree pot\n",
    "data = df2[[ 'educ', 'salbegin','jobtime', 'prevexp', 'minority', 'g1','Manager','Technical Architect']]\n",
    "# var - variance fraction to explain the PCA\n",
    "# df - pandas dataframe of values fo which PCA is to be computed\n",
    "# Y - predicted variable\n",
    "# do_visualize - boolean to show visualization or not\n",
    "# returns the pca value, the dataframe of PC computed values, the labels for PC and the percentage of variance\n",
    "\n",
    "def pca_scree(var, df, Y, do_visualize= True):\n",
    "    \n",
    "    pca_scl = PCA(var) \n",
    "    pca_scl.fit(df)\n",
    "    princ_comp= pca_scl.transform(df)\n",
    "    print(\"Explained variance ratio:: \", pca_scl.explained_variance_ratio_)\n",
    "    print(\" No. of components:: \", abs(pca_scl.n_components_))\n",
    "    per_var =np.round(pca_scl.explained_variance_ratio_*100, decimals=3)\n",
    "    labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    "    \n",
    "    pca_df = pd.DataFrame(princ_comp, columns=labels)\n",
    "    pca_df=pd.concat([pca_df,Y],axis=1)\n",
    "    \n",
    "    if do_visualize:\n",
    "        plt.bar(x= range(1,len(per_var)+1),height= per_var,tick_label = labels)\n",
    "        plt.ylabel('Percentage of variance')\n",
    "        plt.xlabel('PCA components')\n",
    "        plt.title('Scree Plot')\n",
    "        plt.show()\n",
    "        \n",
    "       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio::  [0.99980118]\n",
      " No. of components::  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-cfb7115f3247>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"salary\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpca_scl2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpca_df2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mper_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_scree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.90\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(data,df2[\"salary\"],test_size =0.2)\n",
    "pca_scl2,pca_df2,labels,per_var = pca_scree(0.90, Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
